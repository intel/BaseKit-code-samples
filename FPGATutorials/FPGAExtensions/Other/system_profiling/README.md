# FPGA Tutorial: Using the Intercept Layer for OpenCL* Applications to Identify Optimization Opportunities

| Optimized for                     | Description
---                                 |---
| OS                                | Linux* Ubuntu* 18.04
| Hardware                          | Intel(R) Programmable Acceleration Card (PAC) with Intel(R) Arria(R) 10 GX FPGA
| Software                          | Intel(R) oneAPI DPC++ Compiler (Beta) 

_Notice: Not supported on Windows* as compiling for FPGA Hardware is not supported in Windows*_

## Purpose
This tutorial demonstrates how to use the Intercept Layer for OpenCL* Applications, an open-source tool, to perform system-level profiling on a design and reveal areas for improvement.

## Key Concepts
This tutorial covers the following concepts:
* Detailed description of the Intercept Layer for OpenCL* Applications tool
* Procedure of setting up the Intercept Layer for OpenCL* Applications tool
* Determine when to apply double-buffering using the Intercept Layer for OpenCL* Applications tool

## The Intercept Layer for OpenCL* Applications

The Intercept Layer for OpenCL* Applications is an open-source tool that you can use to profile oneAPI designs at a system-level. Although it is not part of the oneAPI toolkit installation, it is freely available on GitHub.

This tool serves the following purpose:
* Intercept host calls before they reach the device in order to gather performance data and log host calls. 
* Provide data to visualize the calls through time, and can separate them into *queued*, *submitted*, and *execution* sections for a better understanding of the execution. 
* Identify gaps (using visualization) in the runtime that may be leading to inefficient execution and throughput drops.

**Note:** The Intercept Layer for OpenCL* Applications tool has a different purpose than the Intel® FPGA Dynamic Profiler for DPC++, which provides information about the kernels themselves, and can help optimize the hardware. Together, these tools can be used to optimize both host and device side execution.

The Intercept Layer has different options for capturing different aspects of the host run, and these options are described in its documentation. This tutorial uses the call-logging and device timeline features that print information about the calls made by the host during execution.

You can view visualizations of this data in the following methods:
* This tutorial uses the JSON files generated by the Intercept Layer for OpenCL Applications that contain device timeline information. You can open these JSON files in the Google* Chrome trace event profiling tool, which provides a visualization of the data.
* The Intercept Layer for OpenCL Applications contains a python script that parses the timeline information into a Microsoft* Excel file, where it is presented both in a table format and in a bar graph.

Use the visualized data to identify gaps in the runtime where events are waiting for something else to finish executing. While it is not possible to eliminate all the gaps, you might be able to eliminate gaps caused by dependencies that can be avoided.

This tutorial is based on the *double-buffering* optimization. Double-buffering allows host data processing and host transfers to the device-side buffer to occur in parallel with the kernel execution on the FPGA device. This parallelization is useful when the host performs any combination of the following actions between consecutive kernel runs:
* Preprocessing 
* Postprocessing 
* Writes to the device buffer 
 
By running host and device actions in parallel, execution gaps between kernels are removed as they no longer have to wait for the host to finish its operation. You can clearly see the benefits of double-buffering with the visualizations provided by the Intercept Layer output.

## Setting up the Intercept Layer for OpenCL* Applications
The Intercept Layer for OpenCL* Applications is available on GitHub at the following URL: <https://github.com/intel/opencl-intercept-layer>

To set up the Intercept Layer for OpenCL* Applications, perform the following steps:

1) Download Intercept Layer for OpenCL* Applications version 2.2.1 or later from GitHub at the following URL: 

   <https://github.com/intel/opencl-intercept-layer>

2) Build the Intercept Layer according to the instructions provided in [How to Build the Intercept Layer for OpenCL* Applications](https://github.com/intel/opencl-intercept-layer/blob/master/docs/build.md). Ensure that you have set `ENABLE_CLILOADER=1` when running cmake (for example. `run “cmake -DENABLE_CLILOADER=1 ..”`). After the cmake step, `make` must be run in the build directory - this step builds the `cliloader` loader utility.

    The `cliloader` executable should now exist in the `<path to opencl-intercept-layer-master download>/<build dir>/cliloader/` directory. Add this directory to your `PATH` environment variable if you wish to run multiple designs using `cliloader`.

    You can now pass your executables to `cliloader` to run them with the intercept layer. For details about the `cliloader` loader utility, see [cliloader: A Intercept Layer for OpenCL* Applications Loader](https://github.com/intel/opencl-intercept-layer/blob/master/docs/cliloader.md).

3) Set `cliloader` and other Intercept Layer options.

    If you run multiple designs with the same options, set up a `clintercept.conf` file in your home directory. You can also set the options as environment variables by prefixing the option name with `CLI_`. For example, the `DllName` option can be set through the `CLI_DllName` environment variable. For a list of options, see *Controls* in [How to Use the Intercept Layer for OpenCL Applications](https://github.com/intel/opencl-intercept-layer/blob/master/docs/controls.md).

    For this tutorial, set the following options:

| Options/Variables                                                                       | Description                                                                                                         |
| ---                                                                                     | ---                                                                                                                 |
| `DllName=$CMPLR_ROOT/linux/lib/libOpenCL.so`                  | The intercept layer must know where `libOpenCL.so` file from the original oneAPI build is.                          |
| `DevicePerformanceTiming=1` and `DevicePerformanceTimelineLogging=1`                    | These options print out runtime timeline information in the output of the executable run.                           | 
| `ChromePerformanceTiming=1`, `ChromeCallLogging=1`, `ChromePerformanceTimingInStages=1` | These variables set up the chrome tracer output, and ensure the output has Queued, Submitted, and Execution stages. |
   

These instructions set up the `cliloader` executable, which provides some flexibility by allowing for more control over when the layer is used or not used. If you prefer a local installation (for a single design) or a global installation (always ON for all designs), follow the instructions at [How to Install the Intercept Layer for OpenCL Applications](https://github.com/intel/opencl-intercept-layer/blob/master/docs/install.md).

When you run the host executable with `cliloader <executable> [executable args]` command, the `stderr` output contains lines as shown in the following example:
```
Device Timeline for clEnqueueWriteBuffer (enqueue 1) = 63267241140401 ns (queued), 63267241149579 ns (submit), 63267241194205 ns (start), 63267242905519 ns (end)
```

These lines give the timeline information about a variety of oneAPI runtime calls. After the host executable finishes running, there is also a summary of the performance information for the run.

After the executable runs, the data collected will be placed in the `CLIntercept_Dump` directory, which is in the home directory by default. Its location can be adjusted using the `DumpDir=<directory where you want the output files>` `cliloader` option. `CLIntercept_Dump` contains a file called `clintercept_trace.json`. You can load this JSON file in the Google* Chrome trace event profiling tool (chrome://tracing/) to visualize the timeline data collected by the run.

For this tutorial, this visualization appears as shown in the following example:

![](full_example_trace.PNG)

This visualization shows different calls executed through time. The X-axis is time, with the scale shown near the top of the page. The Y-axis shows different calls that are split up in several ways.

The left side (Y-axis) has two different types of numbers:
* Numbers that contain a decimal point. 
   * The part of the number before the decimal point orders the calls approximately by start time. 
   * The part of the number after the decimal point represents the queue number the call was made in.
* Numbers that do not contain a decimal point. These numbers represent the thread ID of the thread being run on in the operating system.

The colors in the trace represent different stages of execution: 
* Blue during the *queued* stage
* Yellow during the *submitted* stage
* Orange for the *execution* stage

Look for gaps between consecutive execution stages and kernel runs to identify possible areas for optimization.


## Applying Double-Buffering Using the Intercept Layer for OpenCL* Applications

The double-buffering optimization can help minimize or remove gaps between consecutive kernels as they wait for host processing to finish. These gaps are minimized or removed by having the host perform processing operations on a second set of buffers while the kernel executes. With this execution order, the host processing is done by the time the next kernel can run, so kernel execution is not held up waiting for the host. For a more detailed explanation of the optimization, refer to the `double_buffering` advanced tutorial, which can be found in the "BestPractices/double_buffering" folder when navigating from the main FPGA tutorials screen.

In this tutorial, the first three kernels are run without the double-buffer optimization, and the next three are run with it. The kernels were run on an Intel® Programmable Acceleration Card with Intel® Arria® 10 GX FPGA when the intercept layer data was collected. The change made by this optimization can be clearly seen in the Intercept Layer for OpenCL* Applications trace:

![](with_and_without_double_buffering.PNG)

Here, the kernel runs named `_ZTS10SimpleVpow` can be recognized as the bars with the largest execution time (the large orange bars). Double buffering removes the gaps between the kernel executions that can be seen in the top trace image. This optimization improves the throughput of the design, as explained in the `double_buffering` tutorial.

The Intercept Layer for OpenCL* Applications makes the need for and benefits of the optimization clear. Use the Intercept Layer tool on your designs to identify scenarios where you can apply double buffering (and other optimizations).

## Building the Example Design (Linux)
Perform the following steps:

**NOTE:** CMake is necessary to build the design. 

1. Run `cmake` to install the design into the `build` directory from the design directory using:

  ```
  mkdir build
  cd build
  cmake ..
  ```

2. Compile the design through the generated `Makefile`. The following three targets are provided that match the recommended development flow:

   * Compile and run on a CPU host device:

     ```
     make cpu_host
     ./double_buffering.cpu_host
     ```

   * Compile and run on the FPGA emulator:

     ```
     make fpga_emu
     ./double_buffering.fpga_emu
     ```

   * Compile and run on the FPGA hardware:

     ```
     make fpga
     ./double_buffering.fpga
     ```

3. Download the design, compiled for FPGA hardware, from this location: [download page](https://www.intel.com/content/www/us/en/programmable/products/design-software/high-level-design/one-api-for-fpga-support.html)

If you have the Intercept Layer for OpenCL* Applications tool set up, including setting all of the necessary `cliloader` options, you can preface any of the execution commands with `cliloader` to extract system-level profiling information during the run. For example, the following command executes FPGA emulation with the Intercept Layer for OpenCL* Applications:

```
cliloader ./double_buffering.fpga_emu
```

When running non-FPGA-hardware targets, the profiling information extracted is different from what is described in this tutorial, and the optimization may not show a significant benefit.

## Building the Example Design in Third-Party Integrated Development Environments (IDEs)

You can compile and run this tutorial in the Eclipse* IDE (in Linux*). For instructions, refer to the following link: [Intel(R) oneAPI DPC++ FPGA Workflows on Third-Party IDEs](https://software.intel.com/en-us/articles/intel-oneapi-dpcpp-fpga-workflow-on-ide)